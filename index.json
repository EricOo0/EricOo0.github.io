[{"categories":["指南","blog"],"content":"Hugo+gitpage搭建属于自己的个人博客 对于不熟悉前端技术的同学来说，可以通过静态博客生成器自动将我们写的markdown笔记转化成静态html页面，放到网站上，给我们省去了很多麻烦事。 常用的三个静态博客生成器： Jekyll Hugo Hexo 而gitpage有静态页面托管的功能，省去了我们部署web服务器的精力和开销。 本文将介绍如何使用gitpage + Hugo来搭建属于自己的blog。 1、创建github仓库 创建一个github仓库，用于存放hugo生成的代码以及托管我们的博客。 仓库的名字为yourusername.github.io： 如果有自己的域名可以修改为自己的域名，这样就可以通过域名访问到你的博客： 2、本地安装HUGO 1、 安装HUGO 根据安装指南安装hugo工具：Install hugo 博主在macos下的安装方法： brew install hugo Hugo version 当出现hugo版本号则证明安装成功 Git 的安装方法此处不赘述了。 3、利用hugo建立自己的网站目录 进入想要存放网站的目录，如home目录下 cd / hugo new site my-blog #my-blog是你的网站文件夹名字 然后去选择一个自己喜欢的模版：Tranquilpeak 会相对容易上手一点 Hugo Themes: https://themes.gohugo.io 将主题clone到本地 cd /my-blog # 进入网站目录 mkdir -p themes # 创建 “themes” 目录。 cd themes git clone https://github.com/Track3/hermit.git hermit # 将 hermit 主题克隆到 hermit目录 4、配置网站 将下载好的模版中的配置文件( themes/hermit/exampleSite/config.toml )复制到网站根目录下(/my-blog) 在 Hugo 网站文件夹的根目录下/my-blog ，打开 config.toml 文件 根据所选主题编辑config.toml,修改一些配置；一般将baseurl修改为你的网站域名(最好带上协议：http://example.com)，以及一些必要信息 5、新建一篇文章 此时你的网站框架已经大致建立好了，当你要新建文章时，利用hugo new可以生成一篇文章模版，放在 my-blog/content/post下 hugo new post/my-first-post.md # “my-first-post.md” 是新建文章的文件名。 写完文章后可以本地预览我们的博客了 hugo server -D 使用浏览器打开 http://localhost:1313 预览 如果你对预览效果满意，进入下一步。 如果不满意，编辑 config.toml 配置文件，再次预览 6、构建hugo网站 在网站根目录下执行hugo命令 hugo # 构建你的 Hugo 网站，默认将静态站点保存到 “public” 目录。 7、转化为git库 cd ~/my-blog/public # 生成的 HTML 文件保存在 “public” 目录中，“public” 文件夹会被转换为 Git 库。 git init # 初始化 Git 库。 关联到远方库 git remote add origin https://github.com/yourusername/yourusername.github.io.git git status # 查看当前修改状态。 git add . # 添加所有修改过的文件。你也可以只添加某个文件。 git commit -m “Add a new post” # “Add a new post” 是 commit message. git push -u origin master 此时到github上的setting查看你的gitpage是否生效，生效后即可通过gitpage访问你的博客了，博客页面由你选择的模版决定，也可以自己进行修改。对于不懂前端的人就可以只关注写博文啦。 8、域名 gitpage默认的域名时yourusername.github.io,你也可以去腾讯云或者阿里云之类的地方购买自己的域名，添加dns解析后替换掉默认的域名 9、日常操作 新建文章：hugo new post/文章名.md 删除文章： 删除两处文件 在目录 /post 、/public 下找到对应文件进行删除 其中 public 下文件不删除也不影响显示，只是该文件就会一直存在，另外该目录下即便文件（除.git)删错或者全部删除也是不影响的，应为 hugo 命令会全部重建 修改文章则直接在post下的文章修改即可 操作完成后使用hugo命令重构 git 上传到github更新博客 10、增加评论功能 一般hugo模版都支持disqus和gitalk来做评论系统，但国内disqus被墙效果可能不太好 disqus 在hugo搭建的静态页面添加hugos很简单，只需要在config.toml中修改 disqusShortname = “example-com” 即可 因此需要先去disqus官网注册你的网站信息。 https://disqus.com/ 选择get started注册账户 选择 I want to install Disqus on my site 填写相关信息然后获得disqusShortname，就是你填写的website name，点(.)会被替换成(-) 修改config文件后即可使用 如果出现无法加载问题，可能说没有挂梯子或者你的baseurl设置有问题，一般要带上协议如http://baseurl gitalk gitalk 首先在博客repo的设置里开启issue功能 https://github.com/settings/developers 创建一个oath application Homepage URL和Authorization callback URL填写网站地址 application 注册成功后 将Client ID，Client secrets，repo name，username等信息填到config.toml中，一般支持gitalk的模版都有相关选项 ","date":"2022-01-15","objectID":"/post/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8hugo+githubpage%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:0:0","tags":["Git","blog"],"title":"如何使用hugo+githubpage搭建个人博客","uri":"/post/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8hugo+githubpage%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["mysql"],"content":"数据库的基本知识框架 SQL\u0026\u0026Redis 结构： 连接层：连接处理–连接池，用户鉴权，安全处理 MySQL服务层：提供数据管理，sql解释，优化等 存储引擎层：实际存储数据的系统 Sql搜索可以考虑的数据结构 目标：高效，快速 哈希表：O（1）的处理速度，单点搜索快但是不适合范围查找，排序 二叉树：O（logn）的时间复杂度，天然的排序特性，但容易不平衡 AVL：严格平衡但是旋转耗时且IO消耗较大，如果深的话（一次查找一个值，进行一次IO） B树：有序数组+平衡多叉树;每个子节点可以存放多个值，树深度降低，适合查找 B+树：有序数组链表+平衡多叉树;每个子节点不存放值，只存放索引（地址），在叶子节点存放所有的数据，且用链表链接所有叶子节点（更适合范围查找，减少磁盘IO次数），每次查询需要的次数是一样的 Redo_log 和 undo_log 1、概念： ​ undo log是逻辑日志，记录是操作记录日志，redo log是物理日志，记录的是新数据；undo log不是redo log的逆向过程 2、用处： ​ undo log是为了保证事务原子性而设计的，redo log是为了保证事务持久性设置的。 ​ undo log在InnoDB中用来实现多版本控制mvcc，执行rollback操作时，undo log可以作为事务回滚的快照读参考。 ​ redo log是备份的最新数据位置，系统冗机时，只要重启mysql服务，就可以将未持久保存的数据持久到磁盘 3、redo log： 只记录该存储引擎中表的修改，是在物理格式上的日志，它记录的是数据库中每个页的修改。 MariaDB/MySQL是工作在用户空间的，MariaDB/MySQL的log buffer处于用户空间的内存中。要写入到磁盘上的log file中(redo:ib_logfileN文件,undo:share tablespace或.ibd文件)，中间还要经过操作系统内核空间的os buffer，调用fsync()的作用就是将OS buffer中的日志刷到磁盘上的log file中。 水平分表 和 垂直分表 关系型数据库本身比较容易成为系统瓶颈，单机存储容量、连接数、处理能力都有限。当单表的数据量达到1000W或100G以后，由于查询维度较多，即使添加从库、优化索引，做很多操作时性能仍下降严重。此时就要考虑对其进行切分了，切分的目的就在于减少数据库的负担，缩短查询时间。 垂直分库： 垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。例如： 垂直分表： 垂直分表是基于数据库中的\"列\"进行，某个表字段较多，可以新建一张扩展表，将不经常用或字段长度较大的字段拆分出去到扩展表中,通过拆分字段，也可以避免跨页问题。ps: MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销。 水平切分-库内分表： 根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小。 Mysql四大特性： ACID:原子性atomic，一致性consistency，隔离性：isolation，持久性duration 原子性：利用undo_log；失败回滚 持久性：redo_log和刷入磁盘持久化 隔离性：加锁和mvcc 事务实现： 事务的实现依靠redo log：数据库的操作先写到缓存中和redo log buffer里，commit后同步到数据库中，实现持久化 三大范式: 第一范式：字段不可再拆分成子字段 第二范式：各字段都和主键有联系 第三范式：各字段只和主键有全部联系（只依赖于主键） 五大约束： 唯一约束：unique 主键约束 primary 外键约束:foreign 默认约束：default 非空约束：notnull 索引类型 1.普通索引 2.唯一索引 ：索引列的值必须唯一 ，允许null！ 3.主键索引 ：一个表只能有一个主键，不允许有空值 4.组合索引 5.全文索引 聚蔟索引和非聚蔟索引 聚蔟索引：将数据存储与索引放到了一块，找到索引也就找到了数据，一般主键就是聚蔟索引，叶子节点存放了数据；只有一个 非聚蔟索引：又叫二级索引，辅助索引，叶子节点存储的是主键的值 聚蔟索引是innodb的特性，mysiam没有，如果需要使用聚蔟索引，设置主键即可，如果没有主键，会用一个唯一且非空的列为主键，也没有的话innodb会创建一个虚拟主键 数据库回表 通过辅助索引(非聚蔟索引)，找到主键，在查询表中数据的过程叫回表，如果只需要辅助索引的键值，则不需要回表–这种是覆盖索引 不走索引的情况 对索引列使用函数 or的列有的没有建立索引–可以用union查询 索引列是string却用int去查询，(int 可以用 char查询) 联合索引不满足最左匹配 a/ab/abc abc只走a 数据库索引：加快检索表中数据的方法 Mysql索引： 索引可以提高检索速度但会降低更新速度，需要更新索引文件 Mysql主要包含四种隔离状态 读未提交Read Uncommitted：脏读-在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。 读取提交内容Read committed：一个事务只能看见已经提交事务所做的改变 可重复读 ：幻读，提交前读取的数据不变 串行化 数据库事务隔离： 查询隔离等级：SHOW VARIABLES LIKE ‘%isolation’; or SELECT @@session.transaction_isolation; 修改隔离等级： SET[GLOBAL|SESSION]TRANSACTIONISOLATIONLEVEL{REPEATABLEREAD--可重复读。幻读 |READCOMMITTED--已提交读 不可重复读 |READUNCOMMITTED--未提交度 脏读 |SERIALIZABLE} 同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。 mysql有哪几种锁 myisam支持表级锁 innodb支持行锁 读锁写锁（或者叫排他锁共享锁） 间隙锁 MVCC理解 1、什么是MVCC？ 多版本并发控制 https://juejin.cn/post/6871046354018238472 https://juejin.cn/post/6844903986143690765 2、实现方式？ 事务隔离实现两种方式一种是加读写锁(串行化)，另一种就是MVCC. MVCC主要是通过在每一行记录中增加三个字段，与 undo log 中相关记录配合使用，同时加上可见性算法，使得各个事务可以在不加锁的情况下能够同时地读取到某行记录上的准确值（这个值对不同的事务而言可能是不同的）。使用 MVCC，在不加锁的情况下也能读取到准确的数据，大大提高了并发效率。 1、对于数据库中的每条数据，添加三个字段（trx_id;roll_ptr;row_id） 2、当事务对数据进行更新时，会将操作写入undo log，并且更新数据的trx_id和roll_ptr 3、当事务进行查询的时候，通过roll_ptr去找到当前事务能读到的最近历史版本的数据(比较trx_id和read_view) 关键: roll_ptr–版本链 undo日志 read_view read_view-一致性视图 用于可见性判断，事务在创建的时候会生成一个快照，由下列4个部分组成： creator_trx_id:当前事务id m_ids:所有事务的事务id min_trx_id:m_ids里最小的事务id值 max_trx_id:最大事务id 如果是已提交读，那么每一个语句执行前都会重新算出一个新的视图，如果是可重复读，则是执行事务时创建 四种隔离级别，只有「读提交」和「可重复度」两个隔离级别能够使用 MVCC，因此也只有这两个隔离级别会创建一致性视图（read-view） 可重复读会带来幻读的问题，可通过间隙锁解决 select … for update 权限设置： 通过用户名密码登录到账户 Grand 权限（update，drop等）on 表 to 用户 Revoke 撤销权限 存储引擎：负责数据库中的数据的存储和查提取。使用不同的技术将数据存储在 文件或内存中(不同的表结构)；show engine看存储引擎 Myisam：不支持事务，（基于hash）但是插入数据快，适合在插入或选择密集（读或写的多单一业务）数据库，对硬件要求低，表锁：不会发生锁冲突 Innodb：支持事务，支持事务提交和回滚，加入外键约束，适合多重并发（更新密集）的数据库，行锁：容易死锁 Memory：运行在内存上，速度快但容易丢失，不支持事务 sql分区： MySQL在创建表的时候可以通过使用PARTITION BY子句定义每个分区存放的数据。在执行查询的时候，优化器根据分区定义过滤那些没有我们需要的数据的分区，这样查询就可以无需扫描所有分区，只需要查找包含需要数据的分区即可。 create TABLE tblname (upload_date string,FTarget string) PARTITION BY RANGE (upload_date) (partition p_20210615 values less than (20210615) ) 常用分区类型：range；list 查看某个分区信息： show create table partition_test；查看","date":"2022-01-14","objectID":"/post/sql%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:0:0","tags":["mysql"],"title":"数据库基础知识框架","uri":"/post/sql%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["网络"],"content":"计网的基本知识框架 计算机网络 ICMP： ICMP 网络控制消息协议，用于在IP协议中发送控制消息，运行在IP层，用于测试网络状况等 ping和tracroute发送的是ICMP报文 ICMP报文负责差错控制–负责错误报告，不负责错误纠正（IP报文只负责消息传输，不管差错控制） 常见错误：终点不可达，超时，源点抑制 DNS： DNS是域名系统（Domain Name System），是将域名和IP地址的之间进行转换的一项服务gethostbyname 域名转换时会先区浏览器缓存查询域名对应的IP，如果没有，会去本地HOSTS里查询，如果没有才会到DNS服务 器上去寻找。 DNS运行在应用层，域名解析是基于UDP的（快，简单） ARP： ARP地址解析协议，提供IP地址和MAC地址的转换服务；属于网络层 ARP地址请求是广播，向所有用户请求目的IP的mac地址；arp回复是单播。 linux下用 arp -a 查看arp缓存；一个地址在arp缓存中有老化时间，过期会被删除。 arp攻击：arp是一种不安全的协议–arp洪泛 arp欺骗 TCP/IP和UDP部分： TCP和UDP区别 ： Tcp面向连接，需要三次握手四次挥手，是可靠传输;而udp不面向连接是不可靠传输（尽最大努力传输） TCP是字节流而UDP是报文 TCP有拥塞避免（作用于网络）-慢开始，快恢复，快重传，流量控制（作用于接收放，接收窗口），UDP无 TCP适用于文件传输等对可靠性要求高的（邮件，文件传输），UDP适用于实时应用（语言，视频） TCP首部20字节，UDP首部8字节 TCP慢，资源消耗多，udp快，资源消耗少 拥塞避免算法： 发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，发送窗口可能小于拥塞窗口。 慢开始 算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小 拥塞避免 当拥塞窗口大于拥塞门限，采用拥塞避免算法，即拥塞窗口线性增加+1 当发生超时情况–没有收到确认就认为是网络拥塞，慢开始门限设为当前拥塞窗口一半，拥塞窗口设为1 快重传：发送方收到连续三个同一个确认报文，就直接重传，不等超时 快恢复：发送方收到连续三个同一个确认报文，把慢开始门限设为一半，执行拥塞避免算法 TCP报文结构: 头部包含：源目的端口号，序号与确认序号，校验和，报文长度，数据偏移（UDP可能在IP层分片）等 分包和粘包： 当发送间隔很短，包长度很小时，socket内部会把几个报文打包成一个发送 当报文太大的时候，socket内部会拆分成几个报文发送 解决办法：加头部，标明数据长度，或加起止标志 四次挥手的状态： 1、客户端发送请求关闭报文fin ,客户端进入fin_wait1 2、服务器接收fin并回复fin_ack,服务器进入close_wait 3、客户端接收ack，客户端进入fin_wait2; 4、服务器发出关闭请求fin，服务器进入last_ack 5、客户端接收并回复确认，进入time_wait状态 四次挥手是因为全双工，为了双方断开 三次握手 1、客户端发出syn请求，进入Syn_send状态 2、服务器接收syn，回复syn+ack，进入syn_recv状态 3、客户端接收到syn+ack，回复ack，客户端进入established状态 4、服务器接收到ack,进入established 为什么要三次握手，因为tcp是全双工的，需要测速双方的收发能力都是正常的。 * 可以两次握手吗? 不可以，如果只进行两次握手： 1、当服务器的确认丢失的时候，服务器以为成功建立了连接，但客户端却认为没有建立。此时服务器向客户端发送数据会被丢弃 2、客户端发出连接请求超时后到达服务器，服务器仍接收请求发出确认，但客户端此时不需要建立连接，浪费资源 time_wait： 为什么要有time_wait 阶段 1、客户端发送第四次挥手中的报文后，再经过2MSL，可使本次TCP连接中的所有报文全部消失，不会出现在下一个TCP连接中。 2、考虑丢包问题，如果第四挥手发送的报文在传输过程中丢失了，那么服务端没收到确认ack报文就会重发第三次挥手的报文。如果客户端发送完第四次挥手的确认报文后直接关闭，而这次报文又恰好丢失，则会造成服务端无法正常关闭。 3、服务器出现大量time_wait(短链接很多)解决办法：1、修改内核减少time_wait时间 2、设置socket可重用 Close_wait过多怎么解决 客户端一侧发起关闭连接请求，服务器方回复确认后，服务器方会进入close_wait 状态。 close_wait过多的原因：服务端socket忙于读写，并没有close socket，无法进入到last_ack状态 解决方法：1、使用完socket要调用close关闭；设置TCP连接时长–keep_alive_time，强行关闭一些没有活动的连接 如果已经建立了连接，但是客户端突然出现故障了怎么办？ 如果TCP连接已经建立，在通信过程中，客户端突然故障，那么服务端不会一直等下去，过一段时间就关闭连接了。具体原理是TCP有一个保活机制，主要用在服务器端，用于检测已建立TCP链接的客户端的状态，防止因客户端崩溃或者客户端网络不可达，而服务器端一直保持该TCP链接，占用服务器端的大量资源(因为Linux系统中可以创建的总TCP链接数是有限制的)。 初始化双发的序列号；为什么要随机初始化 防止被攻击 UDP最大报文长度： 1480（因为以太网帧长度为1500，ip首部20字节） 第三次握手失败怎么办？ 服务器超时没收到请求重传，5次失败后关闭连接；客户端如果此时发送数据会受到RST响应包 HTTP 部分： http和https区别？ 端口：http-80 https-443 安全性：https有加密机制更安全 协议：http运行在tcp之上，https运行在ssl层上（安全套接字层）而ssl运行在tcp层上。 https过程 HTTPS实际上就是HTTP穿上了SSL/TLS的外套; 增加一层SSL（安全套接字） 密钥磋商过程： 客户端发起一个http请求，连接端口443 服务器把自己的数字证书，公钥等信息发给客户端（非对称密钥） 客户端验证证书合法性，生成对称密钥，用公钥加密后发给服务器 HTTP请求过程： 域名解析（DNS）获得IP -\u003e 对服务器发起TCP连接（3次握手）-\u003e 连接成功后可以发送http请求（post，get）-\u003e服务器响应，发送页面-\u003e浏览器解析渲染 状态码： 2xx：成功响应 3xx:重定向状态码 4xx：客户端错误 5xx:服务器错误 http格式： 请求行（request line-请求方法+url+协议版本）、请求头部（header）、空行和请求数据4个部分 HTTP长连接短链接： Http 1.0：短链接 耗费太多资源，每次发送都有链接 Http 1.1：长连接+心跳机制keeplive –长链接的目的可以复用 比如请求一个网页：如果是短链接-需要建立十几个tcp链接，传输css，js等一系列资源；长链接的话只需要复用一个tcp链接 长链接+连接池–防止高并发占用太多资源 http2.0:特点：多路复用-允许单个连接多个请求 http3.0:基于UDP，主要是快-减少了握手的时间和TLS；解决弱网情况下队头阻塞等问题； http端口号 http端口是80 https是443 HTTP的无连接和无状态 HTTP协议是应用层协议，主要五大特点：支持客户-服务器模式，简单快速，灵活，无连接，无状态 无状态是指协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态，服务器无法判断用户身份。即我们给服务器发送 HTTP 请求之后，服务器根据请求，会给我们发送数据过来，但是，发送完，不会记录任何信息。–（用cookie和session解决） 无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 session和cookie Cookie ​ Cookie是保存在客户端一个小数据块，其中包含了用户信息。当客户端向服务端发起请求，服务端会像客户端浏览器发送一个Cookie，客户端会把Cookie存起来，当下次客户端再次请求服务端时，会携带上这个Cookie，服务端会通过这个Cookie来确定身份。 Session ​ Session是通过Cookie实现的，和Cookie不同的是，Session是存在服务端的。当客户端浏览器第一次访问服务器时，服务器会为浏览器创建一个sessionid，将sessionid放到Cookie中，存在客户端浏览器。比如浏览器访问的是购物网站，将一本《图解HTTP》放到了购物车，当浏览器再次访问服务器时，服务器会取出Cookie中的sessionid，并根据sessionid获取会话中的存储的信息，确认浏览器的身份是上次将《图解HTTP》放入到购物车那个用户。 Token ​ 客户端在浏览器第一次访问服务端时，服务端生成的一串字符串作为Token发给客户端浏览器，下次浏览器在访问服务端时携带token即可无需验证用户名和密码，省下来大量的资源开销。 其他： 什么是nginx: Nginx是一款轻量级的Web服务器、也可以用来做反向代理服务，具有简单的负载均衡； 支持高并发（epoll，","date":"2022-01-14","objectID":"/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:0:0","tags":["网络"],"title":"计算机网络基础知识","uri":"/post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["指南"],"content":"Mac 使用zsh美化终端 MAC终端美化 1、安装oh-my-zsh： sh -c “$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" 但一般会报错 curl: (7) Failed to connect to raw.githubusercontent.com port 443: Connection refused 原因：这个网站是被墙的，需要科学上网 或者复制下方脚本到桌面上并执行，但clone 的步骤可能还是会报错，最好还是翻墙安装，或者自己先clone到国内repo里 #!/bin/sh # # This script should be run via curl: # sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" # or via wget: # sh -c \"$(wget -qO- https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" # or via fetch: # sh -c \"$(fetch -o - https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" # # As an alternative, you can first download the install script and run it afterwards: # wget https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh # sh install.sh # # You can tweak the install behavior by setting variables when running the script. For # example, to change the path to the Oh My Zsh repository: # ZSH=~/.zsh sh install.sh # # Respects the following environment variables: # ZSH - path to the Oh My Zsh repository folder (default: $HOME/.oh-my-zsh) # REPO - name of the GitHub repo to install from (default: ohmyzsh/ohmyzsh) # REMOTE - full remote URL of the git repo to install (default: GitHub via HTTPS) # BRANCH - branch to check out immediately after install (default: master) # # Other options: # CHSH - 'no' means the installer will not change the default shell (default: yes) # RUNZSH - 'no' means the installer will not run zsh after the install (default: yes) # KEEP_ZSHRC - 'yes' means the installer will not replace an existing .zshrc (default: no) # # You can also pass some arguments to the install script to set some these options: # --skip-chsh: has the same behavior as setting CHSH to 'no' # --unattended: sets both CHSH and RUNZSH to 'no' # --keep-zshrc: sets KEEP_ZSHRC to 'yes' # For example: # sh install.sh --unattended # or: # sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" \"\" --unattended # set -e # Track if $ZSH was provided custom_zsh=${ZSH:+yes} # Default settings ZSH=${ZSH:-~/.oh-my-zsh} REPO=${REPO:-ohmyzsh/ohmyzsh} REMOTE=${REMOTE:-https://github.com/${REPO}.git} BRANCH=${BRANCH:-master} # Other options CHSH=${CHSH:-yes} RUNZSH=${RUNZSH:-yes} KEEP_ZSHRC=${KEEP_ZSHRC:-no} command_exists() { command -v \"$@\" \u003e/dev/null 2\u003e\u00261 } fmt_error() { printf '%sError: %s%s\\n' \"$BOLD$RED\" \"$*\" \"$RESET\" \u003e\u00262 } fmt_underline() { printf '\\033[4m%s\\033[24m\\n' \"$*\" } fmt_code() { # shellcheck disable=SC2016 # backtic in single-quote printf '`\\033[38;5;247m%s%s`\\n' \"$*\" \"$RESET\" } setup_color() { # Only use colors if connected to a terminal if [ -t 1 ]; then RED=$(printf '\\033[31m') GREEN=$(printf '\\033[32m') YELLOW=$(printf '\\033[33m') BLUE=$(printf '\\033[34m') BOLD=$(printf '\\033[1m') RESET=$(printf '\\033[m') else RED=\"\" GREEN=\"\" YELLOW=\"\" BLUE=\"\" BOLD=\"\" RESET=\"\" fi } setup_ohmyzsh() { # Prevent the cloned repository from having insecure permissions. Failing to do # so causes compinit() calls to fail with \"command not found: compdef\" errors # for users with insecure umasks (e.g., \"002\", allowing group writability). Note # that this will be ignored under Cygwin by default, as Windows ACLs take # precedence over umasks except for filesystems mounted with option \"noacl\". umask g-w,o-w echo \"${BLUE}Cloning Oh My Zsh...${RESET}\" command_exists git || { fmt_error \"git is not installed\" exit 1 } ostype=$(uname) if [ -z \"${ostype%CYGWIN*}\" ] \u0026\u0026 git --version | grep -q msysgit; then fmt_error \"Windows/MSYS Git is not supported on Cygwin\" fmt_error \"Make sure the Cygwin git package is installed and is first on the \\$PATH\" exit 1 fi git clone -c core.eol=lf -c core.autocrlf=false \\ -c fsck.zeroPaddedFilemode=ignore \\ -c fetch.fsck.zeroPaddedFilemode=ignore \\ -c receive.fsck.zeroPaddedFilemode=ignore \\ --depth=1 --branch \"$BRANCH\" \"$REMOTE\" \"$ZSH\" || { fmt_error \"git clone of oh-my-zsh rep","date":"2022-01-14","objectID":"/post/mac%E7%BB%88%E7%AB%AF%E7%BE%8E%E5%8C%96/:0:0","tags":["zsh","blog"],"title":"Mac 终端美化","uri":"/post/mac%E7%BB%88%E7%AB%AF%E7%BE%8E%E5%8C%96/"},{"categories":["mysql"],"content":"mysql搭建主备同步数据库 ","date":"2022-01-14","objectID":"/post/mysql%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5/:0:0","tags":["mysql"],"title":"Mysql 主备同步","uri":"/post/mysql%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5/"},{"categories":["mysql"],"content":"主从同步数据库作用： ​ 从数据库起备份作用； ​ 主服务器挂掉的时候，从服务器可以起作用； ​ 可以用来做读写分离 ","date":"2022-01-14","objectID":"/post/mysql%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5/:1:0","tags":["mysql"],"title":"Mysql 主备同步","uri":"/post/mysql%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5/"},{"categories":["mysql"],"content":"分工-流程： ​ 主数据服务器：主要用来从业务服务写入数据或者修改更新数据。 ​ 从数据服务器：主要用来读取业务所需要的数据 ​ 二进制日志(bin-log)：用来存储写入以及更新的数据信息的操作 ​ 中继日志：承接主服务器数据信息，转存在从服务器上 ​ I/O线程：监听主服务器是否发生数据更改的行为，有则更新到中继日志上 ​ SQL线程：将主服务器数据更改的数据从中继日志文件中读取操作并写入到从数据服务器中 ​ 当主数据服务器master进行写入数据或者更新数据操作的时候，数据更改会记录在二进制日志（binary log file）中，主服务器master与从服务器slave进行通讯的是I/O线程，它将修改的数据异步复制写入到slave服务器的中继日志（relay log file）中,从服务器slave与中继日志之间通信使用SQL线程，SQL线程可以异步从中继日志中读取数据后再写入到自己的数据库中，就完成了数据的主从同步功能。 ","date":"2022-01-14","objectID":"/post/mysql%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5/:2:0","tags":["mysql"],"title":"Mysql 主备同步","uri":"/post/mysql%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5/"},{"categories":["mysql"],"content":"搭建 1、 centos默认安装的是mariadb，是mysql的一个开源分支，使用基本一致。 先安装maridb-server： yum -y install mariadb mariadb-server 启动服务：service mariadb start 2、 mysql的配置文件位置： /etc/my.cnf 用/usr/bin/mysql -v –help 可查看默认配置从哪读 3、配置数据库 主数据库配置：如图，设置打开二进制日志功能，id为1，需要同步的数据库为master_test； 从数据库配置: 如果需要互为主备，则配置其id为2，配置二进制日志位置 4、在主数据库创建同步用户并授权 grant replication slave on . to ‘slave_test’@‘ip_addr’ identified by ‘123456’; 创建用户’slave_test'@‘ip_addr’并授于replication slave权限，拥有此权限可以查看从服务器，从主服务器读取二进制日志。 用show master status 可以查看master数据库当前正在使用的二进制日志及当前执行二进制日志位置 5、在从服务器上输入命令修改主服务器设置： change master to master_host=‘ip_addr’,master_user=‘slave_test’,master_password=‘123456’,master_log_file=‘mysql-bin-master.000001’,master_log_pos=405; 6、从服务器上启动 slave服务 start slave； 7、 查看slave状态 show slave status\\G 8、如果需要互为主备，则将上述过程反过来重复一遍 如果主数据库原本就有数据，需要先将数据dump到从数据库在启动slave 从数据库的复制方式 默认为异步复制：主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主如果crash掉了，此时主上已经提交的事务可能并没有传到从库上，如果此时，强行将从提升为主，可能导致新主上的数据不完整。 全同步复制：当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。 半同步复制：介于全同步复制与全异步复制之间的一种，主库只需要等待至少一个从库节点收到并且 Flush Binlog 到 Relay Log 文件即可，主库不需要等待所有从库给主库反馈。同时，这里只是一个收到的反馈，而不是已经完全完成并且提交的反馈，如此，节省了很多时间。 4、主从同步在物理上必然有延迟的现象，在业务追求较高一致性时 ​ 1：如果追求数据一致性，可以使用全同步复制或半同步复制； ​ 2:利用数据库中间件，所有的读写都走数据库中间件，通常情况下，写请求路由到主库，读请求路由到从库。当有写操作发生时的一个时间窗口内，把读操作请求到主库，后面在放到从库。 ​ 3:利用缓存，读操作时看看缓存是否命中，命中就去主库读，否则从库读，缓存有超时时间，和同步到从库时间接近，数据在缓冲中则证明可能还没有写入从库。 ","date":"2022-01-14","objectID":"/post/mysql%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5/:3:0","tags":["mysql"],"title":"Mysql 主备同步","uri":"/post/mysql%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5/"},{"categories":["OS"],"content":"操作系统的基本知识框架 # 操作系统 操作系统的基本功能 进程管理和调度，内存分配 ，文件管理，设备管理 ","date":"2022-01-14","objectID":"/post/os%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:0:0","tags":["操作系统"],"title":"OS基础知识","uri":"/post/os%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["OS"],"content":"进程管理 进程和线程的区别： 区别： 1、fork进程是运行着的程序，是CPU资源分配的基本单位；进程有三种状态：运行态，就绪态，阻塞态；进程有自己的地址空间，不同进程之间相互独立，隔离。不同进程之间通过IPC通信（进程间通信）。 2、clone线程是CPU管理和调度的基本单位，程序执行的最小单位，一个进程可以有多个线程。线程之间共享进程资源（代码段，数据端，堆等，打开描述符等），但有自己的独立栈空间和局部变量，通过加锁同步。 3、协程是一种用户态线程，它比线程更加轻量并且协程对于操作系统是并不可见的 线程可以分为： 1、用户级线程-不需要进入内核（内核不知道线程的存在），效率高 2、内核级线程-由内核进行管理，调度 优劣： 多进程比多线程更健壮，一个进程挂了不会影响其他进程，但进程的一个线程挂了整个进程可能就挂了。 维护进程需要系统为他分配空间，建立数据表等操作，进程切换开销大；线程共享进程的资源，线程切换开销小，不需要另外分配空间。 本质区别： 对内核来讲，不区分线程，进程，都是一个task_struct，包含进程的相关信息，只是线程共享进程空间； 进程和线程都是调用do_fork来创建，但传参不一样，（线程有CLONE_VM 标志，这样线程的描述符直接指向父进程的）； 线程是用父进程的一块空间来作为自己的的栈空间（通过mmap从父进程栈里分，固定大小，不可动态增长ulimit -s查看）； 子进程复制父进程的页表和所有打开的文件描述符等–读时共享，写时复制 fork和vfork区别： fork时，父子进程是独立的空间，不会阻塞，但是复制空间对于马上要exec的进程太浪费了。 vfork：vfork并不复制父进程的进程环境，子进程在父进程的地址空间中运行，所以子进程不能进行写操作，并且儿子“霸占”着父亲的房子的时候，就要委屈父亲一下，让他在外面歇着（阻塞），一旦儿子执行了exec或者exit后，相当于儿子买了属于自己的房子，这时候就相当于分家了；如果在子进程里return会导致进程崩掉，因为二者共享内存，return直接把父进程的栈破坏了。 孤儿进程和僵尸进程： 孤儿进程：当子进程还没有结束的时候，父进程先结束了，那么此时的子进程就叫做孤儿进程，此时系统中的1号进程init会接管孤儿进程 僵尸进程： 任何一个子进程在结束后，并不是马上消失掉，而实留下一些资源等待父进程处理，那么僵尸进程就是当子进程比父进程先结束，而父进程又没有释放子进程占用的资源，此时子进程将成为一个僵尸进程。–会占用系统资源和进程id；通过wait/waitpid函数等待子进程并回收资源 进程间通信: 每个进程各自有不同的用户地址空间,任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核,在内核中开辟一块缓冲区,进程A把数据从用户空间拷到内核缓冲区,进程B再从内核缓冲区把数据读走,内核提供的这种机制称为进程间通信: 管道–半双工，单向流动，父子进程间，固定结构（固定写端和读端），存在内存中，不属于文件系统；无格式字节流 命名管道–可以不同进程，文件形式存在 消息队列–消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列 ID）来标识。不一定先进先出 共享内存 –mmap实现 信号量 Socket 线程 不同的线程的什么内存空间共享，什么内存空间不共享？ 线程创建时共享进程的代码端和堆，数据段(全局变量)，打开的描述符等；线程有自己独立的栈空间和寄存器 线程同步的方式有哪些？ 互斥锁 一个时间只能有一个访问 信号量 一个时间可以有若干个访问 自旋锁 读写锁 线程同步： 互斥量：当有线程占用资源，当前线程会阻塞（休眠，放弃cpu）–上下文切换开销大 读写锁：只有一个写锁，可以有多个读锁 条件变量 自旋锁：资源被占用的时候处于忙等待的状态（自旋占用cpu） 屏障：屏障允许每个线程等待，直到所有的合作线程都达到某一点 进程切换: 进程切换的上下文 上下文：操作系统保持跟踪进程运行所需的所有状态信息，这种状态，也就是上下文，它包括许多信息，例如PC和寄存器文件的当前值，以及主存的内容。 当CPU需要切换到另一个进程时（阻塞或者时间片到了等情况），需要保持当前进程的所有状态（即保留上下文），进程的PCB程序控制块保存了当前程序的运行状态（堆 栈 指针等） 内核态中不区分进程和线程，线程是轻量级进程，都使用task_struct结构保存；线程切换比进程切换更快，损耗更小 -（不用重新申请空间，所以开销小） 进程切换和线程切换的区别： ​ 切换期间，陷入内核态，程序运行信息更新到进程PCB中，找到要切换的进程PCB，取出PCB的信息，开始执行新进程。 ​ 区别：进程切换需要进行虚拟内存的切换–页表的切换 ​ 创建进程的时候–会将内核页表复制给进程页表–不确定 ？ ","date":"2022-01-14","objectID":"/post/os%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:1:0","tags":["操作系统"],"title":"OS基础知识","uri":"/post/os%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["OS"],"content":"内存管理 大小端: 计算机是以字节为单位存储的，每个地址单位对应一个字节(8bit).实际的数据是大于8bit的–int 4字节，double 8字节。 所以实际存储时要对这些字节进行安排 大端：数据的高位放在内存低地址，数据的地位放在内存高地址 小端：数据的高位放在内存高地址，数据低位放在内存低地址 windows一般是小端存储；网络序一般是大端； 如何判断大小端： 1、用union联合体（所有成员有相同的起始地址），定义一个char和一个int；int union.i=1;如果union.c=1，则为小端，否则大端 2、强制类型转换，把int i=1–\u003eint c=(char) i; 如果c是1则为小端 分页分段机制 分页： 用户程序的地址空间被划分成若干固定大小（4k）的区域，称为\"页\"，相应地，内存空间分成若干个物理块，页和块的大小相等。可将用户程序的任一页放在内存的任一块中，实现了离散分配。 将整个内存划分成许多大小相等的页面，每个进程的地址空间可以由多个页面构成。减少内存碎片 分段： 将用户程序地址空间分成若干个大小不等的段，每段可以定义一组相对完整的逻辑信息。存储分配时，以段为单位，段与段在内存中可以不相邻接，也实现了离散分配。 将整个内存划分为大小不同的段，每个进程的地址空间处于不同的独立段中。内存碎片多 段页式： 用分段方法来分配和管理虚拟内存。程序的虚拟地址空间按逻辑单位分成基本独立的段，而每一段有自己的段名，再把每段分成固定大小的若干页管理物理内存。– 进程和进程之间虚拟地址可以相同–分段的目的是为了更好地实现共享 用分页方法来分配和管理物理内存。即把整个主存分成与上述页大小相等的存储块，可装入作业的任何一页。程序对内存的调入或调出是按页进行的。但它又可按段实现共享和保护。 mmap文件映射过程 进程启动映射过程，在虚拟地址空间中为映射创建虚拟映射区域，为这个区分配一个vm_area_struct，通过这个结构体可以在虚拟内存找到对应的位置 建立vm_area_struct对于的虚拟内存和文件磁盘物理地址的映射–即通过待映射的文件指针，在文件描述符表中找到对应的文件描述符，通过文件描述符，链接到内核“已打开文件集”中该文件的文件结构体（struct file），通过虚拟文件系统inode模块定位到文件磁盘物理地址 进程发起这个虚拟地址的访问，进程的读或写操作访问虚拟地址空间这一段映射地址，通过查询页表，发现这一段地址并不在物理页面上。因为目前只建立了地址映射，真正的硬盘数据还没有拷贝到内存中，因此引发缺页异常；缺页异常进行一系列判断，确定无非法操作后，内核发起请求调页过程；调页过程先在交换缓存空间（swap cache）中寻找需要访问的内存页，如果没有则调用nopage函数把所缺的页从磁盘装入到主存中；之后进程即可对这片主存进行读或者写的操作，如果写操作改变了其内容，一定时间后系统会自动回写脏页面到对应磁盘地址，也即完成了写入到文件的过程。 常用页面置换算法: FIFO:先进先出置换 LRU：最近最少使用 Clock 时钟置换算法：增加一个标志位，当一个页面第一次被载入内存/被访问到，就对他置1，然后当有一页要被置换时，转动指针，如果标志位为1则置0，标志位为0则置换这个页 opt：最优置换，把最长时间不会使用的页面置换出去 COW:copy on write 写时复制 Copy-on-write 读时共享，写时复制；父进程fork子进程的时候，会复制父进程的所有资源，包括打开的描述符和文件等（以只读的方式），即两个进程映射的是同一段物理空间，当子进程要写这段空间时或执行exec会进行重新映射。 ​ https://juejin.cn/post/6844903702373859335 系统调度/IO复用 内核态和用户态: 内核态（ring0）与用户态(ring3)是操作系统的两种运行级别.操作系统通过系统调用将Linux整个体系分为用户态和内核态（或者说内核空间和用户空间），程序一开始都是运行于用户态，当程序需要使用系统资源、访问硬件时，就必须通过调用软中断（80号）进入内核态,使用cpu指令操作硬件。在这种保护模式下，即时程序发生崩溃也是可以恢复的. 用户态和内核态区别？ 内核态运行操作系统程序，操作硬件 用户态则运行用户程序，用户程序要想执行特权指令或操作硬件，需要通过系统调用陷入内核态，从内核态调用 陷入内核态的方式：系统调用，中断，异常 陷阱、中断、异常、信号 陷阱:是有意造成的“异常”，是执行一条指令的结果。又叫”软中断“，基本上是一条指令，告诉内核从用户模式切换到内核模式。示例:在系统调用期间，TRAP指令将强制内核代表进程在内核(内核模式)内执行系统调用代码。 信号:信号由内核生成，并在发生异常时发送到进程。例如，除以零指令将导致内核为该过程生成SIGSEGV信号(段错误)。 异常:这些是由处理器生成的中断（异常是一种错误情况，是执行当前指令的结果，可能被错误处理程序修正，也可能直接终止应用程序。）。示例:除以零。这些本质上是同步的，这意味着处理器知道中断的产生 中断：由硬件生成。示例:由键盘生成的中断，用于在屏幕上键入字符。 静态库和动态库 库是共享程序代码的方式，一般分为静态库和动态库。 静态库：链接时完整地拷贝至可执行文件中，被多次使用就有多份冗余拷贝。.a为后缀 动态库：链接时不复制,只将符号复制，程序运行时由系统动态加载到内存，供程序调用，系统只加载一次，多个程序共用，节省内存。.so为后缀；可用ldd查看 动态连接-占用内存小，方便更新 静态连接：快，不需要依赖其他文件 IO模型 : Epoll，poll，select区别： IO多路复用 Epoll是事件触发机制，没有描述符限制；三个主要函数：epoll_create(int size)；poll_ctl(int epfd， int op， int fd， struct epoll_event *event)； int epoll_wait(int epfd， struct epoll_event *events， int maxevents， int timeout); 核心结构是红黑树和链表-监听的描述符添加到红黑树，epoll_ctr进行管理；触发的描述符通过链表管理 水平触发：只要缓存区不空，就触发可读 边沿触发：只要有新数据到达就触发可读 通过设置events的EPOLLET设置 但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 EPOLL默认是水平触发，设置成边沿触发时要设置成非阻塞IO，因为ET模式下每次读写要循环read、write直到返回EAGAIN错误，如果使用阻塞IO，则会阻塞在最后一次读写，而不是返回错误。 Select和poll是轮询，select用数组，最多1024个描述符，poll是链表，无限制 select的数据存放在用户态，每次调用要把数组复制到内核态，查看描述符的状态；epoll的红黑树直接简历在内核态，效率更高 Epoll有两种触发方式：水平触发：当缓冲区有东西都会触发；边沿触发：当又新的内容进入缓冲区才触发 IO模型 同步阻塞IO(BLOCKING):阻塞在当前位置等待响应 同步非阻塞IO（non-blcking）:指向时如果kernel未准备好回立刻返回一个错误（用户进程会不断询问） 多路复用IO：select，epoll,不需要用户程序不断询问 异步IO：用户发起操作（read）后立刻返回，不对进程产生阻塞。kernel等数据准备好后会把数据拷贝到用户内存，然后给用户进程发送一个signal，报告操作完成；和非阻塞IO的区别：在数据准备好后，非阻塞IO实际上时需要阻塞程序将数据从内核拷贝到用户内存的，而异步IO不需要，内核非阻塞地完成这项任务 信号驱动IO:调用sigaltion系统调用，当内核中IO数据就绪时以SIGIO信号通知请求进程，请求进程再把数据从内核读入到用户空间，这一步是阻塞的。 死锁 死锁是值多个进程各自占有资源，同时阻塞等待其他进程释放资源，造成了循环等待； 死锁的四个条件： 互斥：锁的基本性质，资源只能被一个进程占有 占有和保持：占有资源的进程不会释放，会一直保持直到获取全部需要资源 不可剥夺：进程的资源不可以被其他进程剥夺 循环等待：由于前面的几个性质造成了循环等待； 解决死锁的方法： 死锁预防：打破死锁的四个条件–1、进程一次性获取需要的全部资源，否则就释放；2、获取不到需要的资源则释放自己的资源 死锁避免：银行家算法等，提前计算所有可能，防止出现死锁条件 死锁检测和死锁解除 一般操作系统还会使用鸵鸟策略，直接忽略死锁； Grep,awk,sed-linux三剑客：sed是一个流编辑器 ulimit -c unlimited:开启core ","date":"2022-01-14","objectID":"/post/os%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:2:0","tags":["操作系统"],"title":"OS基础知识","uri":"/post/os%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["指南","Vim"],"content":"Mac/Linux 下Vim一些提高生产力的配置 打开.vimrc文件 \" 设置外观 ————————————- set number “显示行号 set showtabline=0 “隐藏顶部标签栏” set guioptions-=r “隐藏右侧滚动条” set guioptions-=L “隐藏左侧滚动条” set guioptions-=b “隐藏底部滚动条” set cursorline “突出显示当前行” set cursorcolumn “突出显示当前列” set langmenu=zh_CN.UTF-8 “显示中文菜单 \" 编程辅助 ————————————- syntax on “开启语法高亮 set nowrap “设置代码不折行” set fileformat=unix “设置以unix的格式保存文件” set cindent “设置C样式的缩进格式” set tabstop=4 “一个 tab 显示出来是多少个空格，默认 8 set shiftwidth=4 “每一级缩进是多少个空格 set backspace+=indent,eol,start “set backspace\u0026可以对其重置 set showmatch “显示匹配的括号” set scrolloff=5 “距离顶部和底部5行” set laststatus=2 “命令行为两行” \" 其他杂项 ————————————- set mouse=a “启用鼠标” set selection=exclusive set selectmode=mouse,key set matchtime=5 set ignorecase “忽略大小写” set incsearch set hlsearch “高亮搜索项” set noexpandtab “不允许扩展table” set whichwrap+=\u003c,\u003e,h,l set autoread \" 支持中文 ————————————- set fileencodings=utf-8,gb2312,gbk,gb18030 set termencoding=utf-8 set fileformats=unix set encoding=prc ","date":"2022-01-14","objectID":"/post/vim%E9%85%8D%E7%BD%AE/:0:0","tags":["Vim","blog"],"title":"Vim配置","uri":"/post/vim%E9%85%8D%E7%BD%AE/"},{"categories":["Go","框架"],"content":"Golang 常用的框架学习 日志框架Zap import “go.uber.org/zap” 日志等级分为Debug，Info，Warn，Error，Fatal import( \"go.uber.org/zap\" ) func main(){ var logger *zap.Logger logger,_=zap.NewProduction() logger.Debug(\"this is a debug msg!\") // 这行不会打印，因为默认日志级别是 INFO logger.Info(\"this is a Inofo msg!\") // INFO 级别日志，这个会正常打印 logger.Warn(\"this is a Warn msg!\")// WARN 级别日志，这个会正常打印 logger.Error(\"this is a error msg!\") // ERROR 级别日志，这个会打印，并附带堆栈信息 logger.Fatal(\"this is a fatal msg! I will exit after this log\")// FATAL 级别日志，这个会打印，附带堆栈信息，并调用 os.Exit 退出 } SugaredLogger 定制日志格式 前面的zap.NewProduction() – 实际上是创建了一个带了预置配置的 zap.Logger，使用zap.New(core zapcore.Core, options …Option)可以手动传递所有配置项，zapcore.Core需要 3 个配置： Encoder: 编码器，用于告诉 zap 以什么样的形式写入日志。zap 提供了 jsonEncoder 和 consoleEncoder 两种内置的编码器 WriterSyncer: 告诉 zap 将日志写到哪里，比如文件(os.File) 或标准输出(os.stdout) LevelEnabler: 用于设置 zap.Logger 的日志级别 var sugaredLogger *zap.SugaredLogger writer :=zapcore.AddSync(os.Stdout) //日志的输出设备可以是file或标准输出 encoder := zapcore.NewJSONEncoder(zap.NewProductionEncoderConfig())//创建编码格式 core := zapcore.NewCore(encoder,writer,zapcore.DebugLevel)//创建一个core，日志格式 logger:= zap.New(core) sugaredLogger = logger.Sugar() sugaredLogger.Debugf(\"i am debug, using %s\", \"sugar\") // 这行不会打印，因为默认日志级别是 INFO sugaredLogger.Infof(\"i am info, using %s\", \"sugar\") // INFO 级别日志，这个会正常打印 sugaredLogger.Warnf(\"i am warn, using %s\", \"sugar\") // WARN 级别日志，这个会正常打印 sugaredLogger.Errorf(\"i am error, using %s\", \"sugar\") // ERROR 级别日志，这个会打印，并附带堆栈信息 sugaredLogger.Fatalf(\"i am fatal, using %s\", \"sugar\") // FATAL 级别日志，这个会打印，附带堆栈信息，并调用 堆栈和caller信息需要显示的调用才会显示： logger := zap.New(core, zap.AddCaller()) // 增加 caller 信息 需要添加其他自定义字段也可以在New的时候添加 uuid:=\"test\" logger := zap.New(core, zap.AddCaller(), zap.Fields(zapcore.Field{ // 添加 uuid 字段 Key: \"uuid\", Type: zapcore.StringType, String: uuid, })) 文件切割 因为zap本身不支持切割归档日志文件，为了添加日志切割归档功能，用第三方库lumberjack来实现 \"github.com/natefinch/lumberjack\" 修改前面代码中的writer， var sugaredLogger *zap.SugaredLogger //lumberjack 修改writer lumberJackLogger:=\u0026lumberjack.Logger{ Filename: \"./test.log\", MaxSize: 10,//在进行切割之前，日志文件的最大大小（以MB为单位） MaxBackups:5,//旧文件的个数 MaxAge: 1, //天数 Compress: false, } writer :=zapcore.AddSync(lumberJackLogger) //日志的输出设备可以是file或标准输出 服务启动日志是追加不是覆盖 日志格式也可以自定义 writer :=zapcore.AddSync(lumberJackLogger) //自定义时间格式 config := zapcore.EncoderConfig{ MessageKey: \"msg\", //结构化（json）输出：msg的key LevelKey: \"level\",//结构化（json）输出：日志级别的key（INFO，WARN，ERROR等） TimeKey: \"ts\", //结构化（json）输出：时间的key（INFO，WARN，ERROR等） CallerKey: \"file\", //结构化（json）输出：打印日志的文件对应的Key EncodeLevel: zapcore.CapitalLevelEncoder, //将日志级别转换成大写（INFO，WARN，ERROR等） EncodeCaller: zapcore.ShortCallerEncoder, //采用短文件路径编码输出（test/main.go:14 ） EncodeTime: func(t time.Time, enc zapcore.PrimitiveArrayEncoder) { enc.AppendString(t.Format(\"2006-01-02 15:04:05\")) },//输出的时间格式 EncodeDuration: func(d time.Duration, enc zapcore.PrimitiveArrayEncoder) { enc.AppendInt64(int64(d) / 1000000) },// } encoder := zapcore.NewJSONEncoder(config)//创建编码格式 配置解决方案框架Viper Viper是适用于Go应用程序（包括Twelve-Factor App）的完整配置解决方案。它被设计用于在应用程序中工作，并且可以处理所有类型的配置需求和格式。 github.com/spf13/viper viper提供的配置方式的优先级顺序如下(由高到低)： 1.设置显示调用(explicit call to Set) 2.命令行标志(flag) 3.环境变量(env) 4.配置文件(config) 5.远程键/值存储(key/value store) 6.默认值(default) 使用方式： 定义一个要读取的配置文件：config_text.yaml IpAddr:\"127.0.0.1\"Port:3306UserName:\"root\"Password:123456DataBaseName:\"go_test\" type DBconnection struct{ IpAddr string Port int Username string Password int Dbname string } func main{ config := viper.New() //设置要读取的配置名，不加后缀 config.SetConfigName(\"config_text\") //设置配置文件路径,可以设置多个搜索路径 config.AddConfigPath(\"./p1_test\") //设置配置文件类型 config.SetConfigType(\"yaml\") //读取配置 dbconfig := new(DBconnection) err := config.ReadInConfig() if err != nil { panic(fmt.Errorf(\"Fatal error config file: %s \\n\", err)) } config.Unmarshal(\u0026dbconfig) //加码配置并存到dbconfig //打印配置 fmt.Println(dbconfig) } 要让viper持续监控配置实时更新，则在添加config路径后面添加 package main import( \"fmt\" \"github.com/fsnotify/fsnotify\" \"github.com/spf13/viper\" \"time\" ) //用于接受配置的数据结构 type DBconnection struct{ IpAddr string Port in","date":"2022-01-14","objectID":"/post/go%E5%B8%B8%E7%94%A8%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/:0:0","tags":["Go","Web"],"title":"Go 常用框架学习记录","uri":"/post/go%E5%B8%B8%E7%94%A8%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/"},{"categories":["topic1","subtopic1"],"content":"asdadsadadad test ","date":"2022-01-14","objectID":"/post/my-first-post/:0:0","tags":null,"title":"My First Post","uri":"/post/my-first-post/"},{"categories":["topic1","subtopic2"],"content":"asdadsadadad2 test2 ","date":"2022-01-14","objectID":"/post/my-first-post2/:0:0","tags":null,"title":"My First Post2","uri":"/post/my-first-post2/"},{"categories":["指南"],"content":"MacOS下C++ 的vscode开发环境配置 C++开发环境搭建 代码编辑神器 Vscode 1、安装拓展 mac自带已经有c的编译器了所以不用另外安装，终端g++/gcc –version可以查看相关信息，如果没有可以顺便安装xcode，省去一些麻烦，也可以用来写c++代码。win需要下载编译器mingw。 Vscode只需要把c/c++相关的一些工具拓展安装下来： C/C++ C/C++ Clang Command Adapter C/C++ Extension Pack C++ Intellisense C/C++ Runner 2、新建一个.cpp文件 “command+shift+p”打开命令行工具窗口，输入或者选择“Edit Configurations”命令，生成c_cpp_properties.json文件 也可以直接复制下面四个个文件到.vscode文件夹下 c_cpp_properties.json:includepath路径下可以根据自己需要配置 { \"configurations\": [ { \"name\": \"macos-gcc-x64\", \"includePath\": [ \"${workspaceFolder}/**\" ], \"compilerPath\": \"/usr/bin/clang\", \"cStandard\": \"${default}\", \"cppStandard\": \"c++11\", \"intelliSenseMode\": \"macos-gcc-x64\", \"compilerArgs\": [ \"-Wall\", \"-Wextra\", \"-Wpedantic\", \"-stdlib=libc++\", \"-std=c++11\" ] } ], \"version\": 4 } task.json { \"tasks\": [ { \"type\": \"cppbuild\", \"label\": \"C/C++: g++ 生成活动文件\", \"command\": \"/usr/bin/g++\", \"args\": [ \"-std=c++11\", \"-g\", \"${file}\", \"-stdlib=libc++\", \"-std=c++11\", \"-o\", \"${fileDirname}/${fileBasenameNoExtension}\" ], \"options\": { \"cwd\": \"${fileDirname}\" }, \"problemMatcher\": [ \"$gcc\" ], \"group\": \"build\", \"detail\": \"调试器生成的任务。\" }, { \"type\": \"cppbuild\", \"label\": \"C/C++: g++ 生成活动文件 ver(1)\", \"command\": \"/usr/bin/g++\", \"args\": [ \"-g\", \"${file}\", \"-stdlib=libc++\", \"-std=c++11\", \"-o\", \"${fileDirname}/${fileBasenameNoExtension}\", \"-Wall\", \"-Wextra\", \"-Wpedantic\" ], \"options\": { \"cwd\": \"${fileDirname}\" }, \"problemMatcher\": [ \"$gcc\" ], \"group\": \"build\", \"detail\": \"调试器生成的任务。\" }, { \"type\": \"cppbuild\", \"label\": \"C/C++: g++ 生成活动文件 ver(2)\", \"command\": \"/usr/bin/g++\", \"args\": [ \"-g\", \"${file}\", \"-o\", \"${fileDirname}/${fileBasenameNoExtension}\", \"-Wall\", \"-Wextra\", \"-Wpedantic\", \"-stdlib=libc++\", \"-std=c++11\" ], \"options\": { \"cwd\": \"${fileDirname}\" }, \"problemMatcher\": [ \"$gcc\" ], \"group\": { \"kind\": \"build\", \"isDefault\": true }, \"detail\": \"调试器生成的任务。\" } ], \"version\": \"2.0.0\" } setting.json { \"C_Cpp_Runner.warnings\": [ \"-Wall\", \"-Wextra\", \"-Wpedantic\" ], \"C_Cpp_Runner.compilerArgs\": [ \"-stdlib=libc++\", \"-std=c++11\" ], \"C_Cpp_Runner.includePaths\": [], \"C_Cpp_Runner.linkerArgs\": [], \"C_Cpp_Runner.cStandard\": \"\", \"C_Cpp_Runner.cppStandard\": \"c++11\", \"C_Cpp_Runner.excludeSearch\": [], \"C_Cpp_Runner.enableWarnings\": true, \"C_Cpp_Runner.warningsAsError\": false, \"C_Cpp_Runner.cppCompilerPath\": \"/usr/bin/clang++\", \"code-runner.executorMap\": { \"javascript\": \"node\", \"java\": \"cd $dir \u0026\u0026 javac $fileName \u0026\u0026 java $fileNameWithoutExt\", \"c\": \"cd $dir \u0026\u0026 gcc $fileName -o $fileNameWithoutExt \u0026\u0026 $dir$fileNameWithoutExt\", \"cpp\": \"cd $dir \u0026\u0026 g++ $fileName -std=c++11 -o $fileNameWithoutExt \u0026\u0026 $dir$fileNameWithoutExt\", \"objective-c\": \"cd $dir \u0026\u0026 gcc -framework Cocoa $fileName -o $fileNameWithoutExt \u0026\u0026 $dir$fileNameWithoutExt\", \"php\": \"php\", \"python\": \"python -u\", \"perl\": \"perl\", \"perl6\": \"perl6\", \"ruby\": \"ruby\", \"go\": \"go run\", \"lua\": \"lua\", \"groovy\": \"groovy\", \"powershell\": \"powershell -ExecutionPolicy ByPass -File\", \"bat\": \"cmd /c\", \"shellscript\": \"bash\", \"fsharp\": \"fsi\", \"csharp\": \"scriptcs\", \"vbscript\": \"cscript //Nologo\", \"typescript\": \"ts-node\", \"coffeescript\": \"coffee\", \"scala\": \"scala\", \"swift\": \"swift\", \"julia\": \"julia\", \"crystal\": \"crystal\", \"ocaml\": \"ocaml\", \"r\": \"Rscript\", \"applescript\": \"osascript\", \"clojure\": \"lein exec\", \"haxe\": \"haxe --cwd $dirWithoutTrailingSlash --run $fileNameWithoutExt\", \"rust\": \"cd $dir \u0026\u0026 rustc $fileName \u0026\u0026 $dir$fileNameWithoutExt\", \"racket\": \"racket\", \"scheme\": \"csi -script\", \"ahk\": \"autohotkey\", \"autoit\": \"autoit3\", \"dart\": \"dart\", \"pascal\": \"cd $dir \u0026\u0026 fpc $fileName \u0026\u0026 $dir$fileNameWithoutExt\", \"d\": \"cd $dir \u0026\u0026 dmd $fileName \u0026\u0026 $dir$fileNameWithoutExt\", \"haskell\": \"runhaskell\", \"nim\": \"nim compile --verbosity:0 --hints:off --run\", \"lisp\": \"sbcl --script\", \"kit\": \"kitc --run\", \"v\": \"v run\", \"sass\": \"sass --style expanded\", \"scss\": \"scss --style expanded\", \"less\": \"cd $dir \u0026\u0026 lessc $fileName $fileNameWithoutExt.css\", \"FortranFreeForm\": \"cd $dir \u0026\u0026 gfortran $fileName -o $fileNameWithoutExt \u0026\u0026 $dir$fileNameWithoutExt\", \"fortran-modern\": \"cd $dir \u0026\u0026 gfortran $fileName -o $file","date":"2022-01-14","objectID":"/post/c++%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/:0:0","tags":["C++","Vscode","blog"],"title":"MacOS下C++开发环境配置","uri":"/post/c++%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"categories":["topic2","subtopic1"],"content":"asdadsadadad3 test3 ","date":"2022-01-14","objectID":"/post/my-first-post3/:0:0","tags":null,"title":"My First Post3","uri":"/post/my-first-post3/"},{"categories":["Linux"],"content":"一些Linux常用命令记录 内存： df -h (-h 使用人类可读的格式) –当前路径下各文件的大小 du -h –各磁盘的大小 网络： tcpdump -i any -n -nn -s0 -A port 11123 （-i 接口 -n 指定将每个监听到数据包中的域名转换成IP地址后显示 -nn 指定将每个监听到的数据包中的域名转换成IP、端口从应用名称转换成端口号后显示 -s 表示从一个包中截取的字节数。0表示包不截断，抓完整的数据包。默认的话 tcpdump 只显示部分数据包,默认68字节 port 端口） netstat -ntlpa显示所有连线中的Socket。-l或–listening 显示监控中的服务器Socket。-p或–programs 显示正在使用Socket的程序识别码和程序名称。-n或–numeric 直接使用IP地址，而不通过域名服务器。 系统： uname -a 查看系统信息 whoami:查看当前登录用户 useradd test -d /home/test/ -p 123创建用户;ps($表示普通用户, #特权用户) su - usrname;切换目录 service：service service.name start/stop/restart/reload/status ；service命令是Redhat Linux兼容的发行版中用来控制系统服务的实用工具，它以启动(start)、停止(stop)、重新启动(restart)和关闭系统服务，还可以显示所有系统服务的当前状态(status)。 nice命令用于以指定的进程调度优先级启动其他的程序。 inode（索引节点）：本质是一个结构体，存储了文件相关的一些数据；指向磁盘上的一个文件 可以用stat 命令查看文件的inode信息 硬链接：多个文件名只指向同一个inode节点；修改一个文件会影响其他所有文件，但是删除一个硬链接不影响其他； 软连接：符号链接；inode节点不同，但a的内容就是b的路径 数据库 yum list | grep mysql命令来查找yum源中是否有MySQL show databases;查看有哪些表 create database [databasename];创建一个数据库 use database；选择数据库 grant previledge on . to ‘slave’@‘ip’ identified by ‘password’；分配权限 show *；查看你想查的信息 在标准的SQL语句中，一次插入一条记录的INSERT语句只有一种形式。 INSERT INTO tablename(列名…) VALUES(列值); 而在MySQL中还有另外一种形式，就是set INSERT INTO tablename SET column_name1 = value1, column_name2 = value2，…; 修改表属性：alter table * modify * ​ update table_name set * 创建分区：create TABLE tblname (upload_date string,FTarget string) PARTITION BY RANGE (upload_date) (partition p_20210615 values less than (20210615) ) 查看某个分区信息： show create table partition_test；查看创建表的语句 show table status；看表是不是分区表 information_schema.PARTITIONS 存储分区信息，可以去这张表查 SELECT * FROM tr p2;查看这个分区的信息 alter table partition_test add partition (partition p_20210616 values less than (20210616));增加分区 数据表备份：create table t2 like t1 ;insert into t2 select * from t1; 数据库更名：RENAME TABLE old_table_name TO new_table_name 字段更名：alter table \u003c表名\u003e change \u003c字段名\u003e \u003c字段新名称\u003e \u003c字段的类型\u003e 数据追加：concat函数–update tblname set col=CONCAT(col,\",https\") where F=\"\" 一些函数：count，distinct 其他 md5sum:计算md5校验值 diff ： 比较文件不同 ； -y并列方式输出 -r 递归对比文件夹下文件 grep :正则表达式提取要加-E ；-o 匹配特定模式 sed 流编辑器，参数 s可以替换文本 参数/g可以匹配所有；cat test |sed ’s/\u0026/\\t/g' 调试 gdb nm+文件名：查看符号表 ldd 看共享依赖库 xargs（英文全拼： eXtended ARGuments）是给命令传递参数的一个过滤器，也是组合多个命令的一个工具。somecommand |xargs -item command shell $()和：命令替换 echo today is $(date “+%Y-%m-%d”) #先完成引号里的命令行，然后将其结果替换出来，再重组成新的命令行 ${}：变量替换 $0：当前Shell程序的文件名 dirname $0，获取当前Shell程序的路径 cd dirname $0，进入当前Shell程序的目录 ls-l :rwx(Owner)r-x(Group)r-x(Other); owner;group; ps: -e显示所有进程，-f 显示UID,PPIP,C与STIME栏位。-u uid or 。username 选择有效的用户id或者是用户名.-x 显示没有控制终端的进程，同时显示各个命令的具体路径。 wc：- c 统计字节数。 - l 统计行数。 - w 统计字数。不加参数显示 行数、字数、字节数、文件名 ls: -l：列出目录下子目录和文件的详细信息;-r排序时按倒序;按最后修改时间排序;-h以容易理解的格式输出内存–ls -lrthz crontab -l 可以看系统的定时任务 -e可以编辑定时任务 eval会对后面的cmdLine进行两遍扫描，如果第一遍扫描后，cmdLine是个普通命令，则执行此命令；如果cmdLine中含有变量的间接引用，则保证间接引用的语义。 source 在当前bash环境下读取并执行FileName中的命令;通常./执行会新建一个子shell basename命令用于打印目录或者文件的基本名称 dirname命令打印文件路径名 trap用法：trap command signal； signal是指接收到的信号，command是指接收到该信号应采取的行动 echo $$：$$表示pid nohub和\u0026区别：都是将进程放到后台执行，但\u0026在账户退出或者控制台关闭的时候进程就被结束；nohub可以在账户退出后继续运行–但账户非正常退出也有可能结束任务，最好用exit退出账户 flag=ps aux | grep ${process} | awk '$11~/ewp_agent$/ {print $2}' |wc -l： / */中间的字符串awk会查找和处理对应行；a~b a中是否包含b =~ :右边式子按正则表达式展开 正则表达式 行首定位:^ 行尾定位:$ 单个字符匹配:. md工具 typora ","date":"2022-01-13","objectID":"/post/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:0:0","tags":["Linux"],"title":"Linux常用命令","uri":"/post/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"}]